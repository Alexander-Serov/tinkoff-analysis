{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy\n",
    "import copy\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from analysis import get_ticker_history, get_etfs_history, History\n",
    "\n",
    "\n",
    "MOSCOW_TIMEZONE = pytz.timezone('Europe/Moscow')\n",
    "\n",
    "# From rest\n",
    "# client = openapi.sandbox_api_client(token)\n",
    "# client.sandbox.sandbox_register_post()\n",
    "# client.sandbox.sandbox_clear_post()\n",
    "# client.sandbox.sandbox_currencies_balance_post(sandbox_set_currency_balance_request={\"currency\": \"USD\", \"balance\": 1000})\n",
    "\n",
    "\n",
    "# From streaming\n",
    "# candle_subs = [{'figi': 'BBG000B9XRY4', 'interval': '1min'}, {'figi': 'BBG009S39JX6', 'interval': '1min'}]\n",
    "# orderbook_subs = [{'figi': 'BBG0013HGFT4', 'depth': 1}, {'figi': 'BBG009S39JX6', 'depth': 3}]\n",
    "# instrument_info_subs = [{'figi': 'BBG000B9XRY4'}, {'figi': 'BBG009S39JX6'}]\n",
    "\n",
    "# run_stream_consumer(token,\n",
    "#                     candle_subs, orderbook_subs, instrument_info_subs,\n",
    "#                     on_candle_event=print_event,\n",
    "#                     on_orderbook_event=print_event,\n",
    "#                     on_instrument_info_event=print_event)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = dt.datetime.now(dt.timezone.utc)\n",
    "start = end - dt.timedelta(weeks=52)\n",
    "interval = 'day'\n",
    "ticker='FXGD'\n",
    "\n",
    "# print(etfs)\n",
    "\n",
    "\n",
    "# print(market.market_candles_get(figi=figi, _from=start.isoformat(), to=end.isoformat(), interval=interval))\n",
    "# ['payload']['instruments'][0]['figi']\n",
    "\n",
    "ticker_history = get_ticker_history(ticker=ticker, start=start, end=end, interval=interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(ticker_history['time'].values, ticker_history['c'])\n",
    "plt.title(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etfs_history, etf_tickers = get_etfs_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and store history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_daily = History(interval='day')\n",
    "# display(hist_daily.data.time.dtype)\n",
    "hist_daily.update(reload=0)\n",
    "hist_daily.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_daily.data.time.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hist_daily.data\n",
    "tickers = hist_daily.tickers\n",
    "# print(data['time'].dtype)\n",
    "\n",
    "M = len(hist_daily.tickers)\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=M-1)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "\n",
    "def get_last_not_nan(lst):\n",
    "    for el in lst[::-1]:\n",
    "        if not np.isnan(el):\n",
    "            return el\n",
    "        \n",
    "    return np.nan\n",
    "\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "ax = plt.gca()\n",
    "ax.set_prop_cycle(color=[scalarMap.to_rgba(i) for i in range(M)])\n",
    "for ticker in tickers:\n",
    "    filter = (data.ticker == ticker)\n",
    "    t = data.loc[filter, 'time'].values\n",
    "    y = data.loc[filter, 'c'].values # / get_last_not_nan(data[ticker+'_c']) * 100\n",
    "#     print(ticker, y)\n",
    "    plt.plot(t, y, label=ticker)\n",
    "    \n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "ax = plt.gca()\n",
    "ax.set_prop_cycle(color=[scalarMap.to_rgba(i) for i in range(M)])\n",
    "for ticker in tickers:\n",
    "    filter = data.ticker == ticker\n",
    "    t = data.loc[filter, 'time'].values\n",
    "    y = data.loc[filter, 'c'] / get_last_not_nan(data.loc[filter, 'c']) * 100\n",
    "    plt.plot(t, y, label=ticker)\n",
    "    \n",
    "plt.ylabel('Price, % (100%=now)')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic calculate_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_daily.calculate_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annualized gain\n",
    "Observations:\n",
    "1. I have learned here that during the day most stocks drop! The mean day change is negative! It's better on average to buy in the afternoon.\n",
    "2. It is strange that even of FXMM my error is so large. That means I can do something. Maybe by increasing the analysis interval? Or producing a more long-term estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hist_daily.data\n",
    "# Drop two weird indices\n",
    "\n",
    "\n",
    "data['day_change'] = data['c'] - data['o']\n",
    "data['norm_day_change'] = data['day_change'] / data['o']\n",
    "data['day_change_c2c']= -data.loc[:, ['ticker', 'c']].groupby(by='ticker').diff(-1)  # close to close change \n",
    "\n",
    "\n",
    "data['dt']= data.loc[:, ['ticker', 'time']].groupby(by='ticker').diff(-1)  # close to close change \n",
    "data.loc[data['dt'] != dt.timedelta(days=-1), 'day_change_c2c'] = np.nan\n",
    "data['rel_day_change_c2c']= data['day_change_c2c'] / data['c']\n",
    "# Make sure it's 1-day intervals only\n",
    "\n",
    "data_filtered = copy.deepcopy(data)\n",
    "data_filtered[(data_filtered['ticker'] == 'RUSE') | (data_filtered['ticker'] ==  'RUSB')] = np.nan\n",
    "\n",
    "\n",
    "tickers = data.ticker.unique()\n",
    "N = len(tickers)\n",
    "data[['day_change_c2c', 'dt', 'rel_day_change_c2c']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily gains plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'rel_day_change_c2c'  # 'day_change'\n",
    "\n",
    "one_day_params = data.loc[:, ['ticker', column]].groupby(\n",
    "    by='ticker').mean().rename(columns={column: 'mean'})\n",
    "one_day_params['var'] = data.loc[:, [\n",
    "    'ticker', column]].groupby(by='ticker').var()\n",
    "one_day_params['std'] = data.loc[:, [\n",
    "    'ticker', column]].groupby(by='ticker').std()\n",
    "one_day_params['count'] = data.loc[:, [\n",
    "    'ticker', column]].groupby(by='ticker').count()\n",
    "one_day_params['SE'] = one_day_params['std'] / np.sqrt(one_day_params['count'])\n",
    "\n",
    "# Drop weird values\n",
    "one_day_params.loc[one_day_params['mean'] > 0.1, 'mean'] = np.nan\n",
    "\n",
    "one_day_params_sorted = one_day_params.sort_values(\n",
    "    by='mean', ascending=False, axis=0)\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Bar(x=one_day_params_sorted.index, y=one_day_params_sorted['mean']))\n",
    "fig.update_layout(xaxis_title='Ticker', yaxis_title='Avg. daily gains, %',\n",
    "                  title='Annulaized gain estimate from close to close daily change')\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Bar(x=one_day_params_sorted.index, y=one_day_params_sorted['mean'], error_y=dict(type='data',\n",
    "                                                                                        array=one_day_params_sorted['SE'].values)))\n",
    "fig.update_layout(xaxis_title='Ticker', yaxis_title='Avg. daily gains, %',\n",
    "                  title='Annulaized gain estimate from close to close daily change Â± SE')\n",
    "fig.show()\n",
    "\n",
    "fig2 = px.violin(data_filtered, y=column, x='ticker', points = 'all')\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'FXIT'\n",
    "# print(data['ticker' == ticker])\n",
    "fig3 = px.violin(data_filtered[data_filtered['ticker'] == ticker], y=column, points = 'all')\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annualized gains. Assume normality and geometric Brownian motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 52*7\n",
    "# means =\n",
    "\n",
    "\n",
    "# According to the solution of the geometric Brownian motion (and assuming it), one gets for the annualized gain\n",
    "yearly_gain_percent = np.exp(one_day_params['mean'] * days) * 100\n",
    "yearly_std_percent = np.sqrt(np.exp(\n",
    "    2 * one_day_params['mean'] * days) * (np.exp(one_day_params['var'] * days) - 1))*100\n",
    "\n",
    "# Drop weird values\n",
    "yearly_gain_percent[yearly_gain_percent > 10**3] = np.nan\n",
    "sorted = yearly_gain_percent.sort_values(ascending=False)\n",
    "\n",
    "fig = go.Figure(\n",
    "    go.Bar(x=sorted.index, y=sorted))\n",
    "fig.update_layout(xaxis_title='Ticker', yaxis_title='Annualized gain, %',\n",
    "                  title='Annulaized gain estimate from close to close daily change')\n",
    "fig.show()\n",
    "\n",
    "print(one_day_params)\n",
    "print(yearly_gain_percent.sort_values(ascending=False))\n",
    "print(yearly_variance_percent_sq)\n",
    "# annualized_gains_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day change "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 200\n",
    "figsize = np.array([1, 2]) * 14\n",
    "quant = 0.98\n",
    "column = 'rel_day_change_c2c'  # 'day_change_c2c'  # 'day_change'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cols = 2\n",
    "rows = math.ceil(len(tickers)/cols)\n",
    "fig, axes = plt.subplots(nrows =rows, ncols = cols, figsize = figsize, gridspec_kw = {'hspace': 0.3})\n",
    "axes = np.array(axes).flat\n",
    "\n",
    "skews = []\n",
    "for ticker, ax in zip(tickers, axes):\n",
    "    dat1=data.loc[data.ticker ==ticker, column]\n",
    "#     dat1 = dat1[np.logical_not(pd.isna(dat1))]\n",
    "#     print(dat1[np.logical_not(pd.isna(dat1))])\n",
    "    \n",
    "    plot_range = np.nanquantile(dat1.values, [1-quant, quant])\n",
    "    dat2 = dat1[(dat1 >= plot_range[0]) & (dat1 <= plot_range[1])]\n",
    "    if len(dat2) > 0:\n",
    "        sns.distplot(dat2.values, bins = bins, ax = ax)\n",
    "    skew = scipy.stats.skew(dat1, nan_policy= 'omit').data\n",
    "    skews.append(skew)\n",
    "    ax.set_title(f'{ticker}, len = {len(dat1)}, skew = {skew:.2f}')\n",
    "#     plot_range = np.quantile(dat1.values, [1-quant, quant])\n",
    "#     ax.set_xlim(plot_range)\n",
    "\n",
    "fig.suptitle(column);\n",
    "    \n",
    "plt.figure()\n",
    "# plt.hist(skews)\n",
    "sns.distplot(skews)\n",
    "print(skews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day change normalized to openning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows =rows, ncols = cols, figsize = figsize, gridspec_kw = {'hspace': 0.3})\n",
    "# axes = np.array(axes).flat\n",
    "\n",
    "# skews = []\n",
    "# for ticker, ax in zip(tickers, axes):\n",
    "#     dat1=data.loc[data.ticker ==ticker, 'norm_day_change']\n",
    "# #     print('Data points: ', len(dat1))\n",
    "#     plot_range = np.quantile(dat1.values, [1-quant, quant])\n",
    "\n",
    "#     dat2 = dat1[(dat1 >= plot_range[0]) & (dat1 <= plot_range[1])]\n",
    "    \n",
    "#     sns.distplot(dat2.values, bins = bins, ax = ax)\n",
    "    \n",
    "#     skew = scipy.stats.skew(dat1)\n",
    "#     skews.append(skew)\n",
    "#     ax.set_title(f'{ticker}, len = {len(dat1)}, skew = {skew:.2f}')\n",
    "\n",
    "\n",
    "# #     plot_range = np.quantile(dat1.values, [1-quant, quant])\n",
    "# #     ax.set_xlim(plot_range)\n",
    "\n",
    "# fig.suptitle('Normalized day changes');\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(skews)\n",
    "# print(skews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gain from normalization is not evident. Abandon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(tickers)\n",
    "cov_matrix = np.full((N, N), np.nan)\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    ser_i = copy.deepcopy(data.loc[data.ticker == tickers[i], [\n",
    "                          'time', column]]).set_index('time')\n",
    "    index_i = set(ser_i.index)\n",
    "    for j in range(N):\n",
    "#         if i==j:  # diagonal elements are not calculated\n",
    "#             continue\n",
    "        ser_j = copy.deepcopy(data.loc[data.ticker == tickers[j], [\n",
    "                              'time', column]]).set_index('time')\n",
    "        common_index = index_i & set(ser_j.index)\n",
    "\n",
    "        cov_matrix[i, j] = (ser_i.loc[common_index, column].cov(ser_j.loc[common_index, column])\n",
    "                            / np.sqrt(ser_i.loc[common_index, column].var() * ser_j.loc[common_index, column].var())\n",
    "                            )\n",
    "\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the correlation matrix\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "cov_df = pd.DataFrame(cov_matrix, columns = tickers, index = tickers)\n",
    "X = cov_df.values\n",
    "d = sch.distance.pdist(X)   # vector of pairwise distances\n",
    "# print('d', d)\n",
    "L = sch.linkage(d, method='complete')\n",
    "# print('L', L)\n",
    "ind = sch.fcluster(L, 0.5*d.max(), 'distance')\n",
    "# print(ind)\n",
    "\n",
    "columns = [cov_df.columns.tolist()[i] for i in list((np.argsort(ind)))]\n",
    "# print(columns)\n",
    "clustered_cov_df = cov_df.loc[columns, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# cov_df = pd.DataFrame(cov_matrix, columns = tickers, index = tickers)\n",
    "\n",
    "# # Sort by max of a column/row\n",
    "# sorted_ticker_inds =  np.sum(np.abs(cov_matrix), axis = 0).argsort()\n",
    "# print(cov_df.columns)\n",
    "# cov_df = cov_df.iloc[sorted_ticker_inds, sorted_ticker_inds]\n",
    "# print(cov_df.columns)\n",
    "\n",
    "# plt.figure(figsize = (10,10))\n",
    "# sns.heatmap(cov_df)\n",
    "fig = px.imshow(clustered_cov_df, x=clustered_cov_df.columns, y = clustered_cov_df.index)\n",
    "fig.show()\n",
    "# ax = plt.gca()\n",
    "# ax.set_xticklabels(cov_df.columns)\n",
    "# ax.set_yticklabels(cov_df.index)\n",
    "# [tickers[ind] for ind in sorted_ticker_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual correlation profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'FXIT'\n",
    "\n",
    "\n",
    "def plot_one_correlation(ticker):\n",
    "\n",
    "    ind = np.argwhere(np.array(clustered_cov_df.columns == ticker))[0,0]\n",
    "    d3 = clustered_cov_df.iloc[ind, :].sort_values(ascending = False)\n",
    "\n",
    "    fig = go.Figure(go.Bar(x=d3.index, y = d3))\n",
    "    fig.update_layout(title_text=ticker + ' correlations', xaxis_title = 'Ticker', yaxis_title = 'Correlation')\n",
    "    fig.show()\n",
    "\n",
    "plot_one_correlation(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_one_correlation('SBMX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_one_correlation('FXMM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_one_correlation('FXTB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "175.11029052734375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
